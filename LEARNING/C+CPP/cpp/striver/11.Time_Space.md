### Time Complexity vs. Time Taken

**Time Complexity**

- **Definition**: Theoretical measure of the running time of an algorithm as a function of input size, expressed in Big O notation (e.g., \( O(n) \), \( O(n^2) \)).
- **Purpose**: Compare efficiency of algorithms independently of hardware or environment.
- **Example**: Searching in an unsorted list of \( n \) elements has a time complexity of \( O(n) \).

**Time Taken**

- **Definition**: Actual time taken by an algorithm to run on specific input and environment.
- **Purpose**: Measure real-world performance.
- **Example**: The same search algorithm might take 2 ms on one computer and 1 ms on a more powerful one.

**Key Differences**

- **Abstraction Level**: Time complexity is theoretical; time taken is practical.
- **Independence**: Time complexity is machine-independent; time taken is machine-dependent.
- **Purpose**: Time complexity compares algorithm efficiency; time taken measures real-world performance.
- **Predictive Power**: Time complexity predicts scalability; time taken provides immediate performance feedback.

## Big O Notation - O()

Big O notation describes the upper bound of the time complexity, representing the worst-case scenario of an algorithm.

### Example

```cpp
for(int i=1; i<=N; i++) {
    cout << "Hello";
}
```

In this example, the time complexity is O(N) because the loop runs `N` times.

## Best Case, Average Case, and Worst Case

Algorithms can have different time complexities based on the input.

- **Best Case:** O(1) - The algorithm performs the best.
- **Average Case:** O(N) - The average performance over a set of inputs.
- **Worst Case:** O(N) - The algorithm performs the worst.

### TC, worst-case scenario:

- **Avoid Constants:** They become insignificant as `N` grows.
- **Avoid lower values:** They have very little impact on the overall complexity.

## Big O, Theta, and Omega Notation

- **Big O (O):** Describes the upper bound or worst-case complexity.
- **Theta (Θ):** Describes the average-case complexity.
- **Omega (Ω):** Describes the lower bound or best-case complexity.

## Examples and Evaluation

### Example 1

```cpp
for(int i=0; i<N; i++) {
    for (int j=0; j<N; j++) {
        // Block of code
    }
}
```

**Evaluate:**
i=0 {j=0,1,2,...N}
i=1 {j=0,1,2,...N}
i=2 {j=0,1,2,...N}
.
.
i=N-1 {j=0,1,2,...N}

In the outer for loop, `i` iterates `N` times. The inner loop also iterates `N` times for each iteration of the outer loop, so the total complexity is `N * N = N^2`.
Thus, the time complexity is O(N^2).

### Example 2

```cpp
for(int i=0; i<N; i++) {
    for (int j=0; j<=i; j++) {
        // Block of code
    }
}
```

**Evaluate:**
i=0 {j=0}
i=1 {j=0,1}
i=2 {j=0,1,2}
.
.
i=N-1 {j=0,1,2,...,N-1}

In the outer for loop, `i` iterates `N` times. The inner loop iterates `i+1` times for each iteration of the outer loop. The total number of iterations is the sum of the first `N` integers, which is `N * (N + 1) / 2`. Therefore, the time complexity is O(N^2).

## Additional Information

### Importance of Time Complexity

Understanding time complexity helps in:

- **Algorithm Comparison:** Comparing different algorithms for efficiency.
- **Optimization:** Improving the performance of code.
- **Scalability:** Ensuring the algorithm performs well as the input size grows.

### Common Time Complexities

- **O(1):** Constant time - The algorithm's performance is independent of the input size.
- **O(log N):** Logarithmic time - The algorithm's performance grows logarithmically.
- **O(N):** Linear time - The algorithm's performance grows linearly.
- **O(N log N):** Linearithmic time - Common in efficient sorting algorithms.
- **O(N^2):** Quadratic time - Common in algorithms with nested loops.
- **O(2^N):** Exponential time - Algorithms with recursive calls that double with each addition to the input size.

### Space Complexity

Space complexity is the amount of memory an algorithm uses relative to the input size. It is calculated as:

Space Complexity = Auxiliary Space + Input Space

Auxiliary Space: The extra space required by the algorithm to solve the problem, excluding the space required to store the input.

Input Space: The space required to store the input data.

int a, b, c;
cin >> a >> b;
c = a + b;

Here, the auxiliary space is O(3) since three integer variables (a, b, and c) are used to solve the problem. The input space is O(2) since two integers (a and b) are taken as input.

If you have an array int a[N], the input space is O(N) then here we say Big Oh of N is the space complexity

Advice: Avoid manipulating the input data directly. Instead, create auxiliary data structures to store intermediate results.

In addition to time complexity, space complexity is also important. It measures the amount of memory an algorithm uses relative to the input size.

Final

In CP servers take about 1s for 10^8 operation since in some contests there are time limits like 1s or 2s so in contests or competitive coding you should limit yourself to using 10^8 operation or 1s or avoid constants or lower values and all
